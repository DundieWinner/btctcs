name: Scheduled Company Analysis

on:
  schedule:
    - cron: '0 2,14,18 * * *'
  push:
    branches:
      - main
    paths:
      - 'companies/**'
      - 'shared_utils/**'
      - 'requirements.txt'
  workflow_dispatch:  # Allow manual triggering

jobs:
  discover-companies:
    name: Discover Companies
    runs-on: ubuntu-latest
    outputs:
      companies: ${{ steps.find-companies.outputs.companies }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Find companies with analysis scripts
        id: find-companies
        run: |
          companies=""
          for dir in companies/*/; do
            if [ -d "$dir" ] && [ -f "${dir}analysis_with_upload.py" ]; then
              company_name=$(basename "$dir")
              if [ -z "$companies" ]; then
                companies="\"$company_name\""
              else
                companies="$companies,\"$company_name\""
              fi
            fi
          done
          
          # Create JSON array
          if [ -z "$companies" ]; then
            companies_json="[]"
          else
            companies_json="[$companies]"
          fi
          
          echo "companies=$companies_json" >> $GITHUB_OUTPUT
          echo "Found companies JSON: $companies_json"
          echo "Found companies: ${companies//,/ }"

  run-analysis:
    name: Run Analysis
    needs: discover-companies
    if: ${{ needs.discover-companies.outputs.companies != '[]' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        company: ${{ fromJson(needs.discover-companies.outputs.companies) }}
      fail-fast: false  # Continue running other companies even if one fails
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ${{ matrix.company }} analysis
        env:
          # S3 Configuration
          S3_BUCKET_NAME: btctcs
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: nyc3
          AWS_ENDPOINT_URL: https://nyc3.digitaloceanspaces.com
          S3_KEY_PREFIX: charts
          
          # Data Configuration
          H100_DATA_URL: ${{ secrets.H100_DATA_URL }}
          METAPLANET_DATA_URL: ${{ secrets.H100_DATA_URL }}
          LQWD_DATA_URL: ${{ secrets.H100_DATA_URL }}

          # Python path configuration
          PYTHONPATH: ${{ github.workspace }}
        run: |
          echo "Running analysis for company: ${{ matrix.company }}"
          cd companies/${{ matrix.company }}
          python analysis_with_upload.py

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.company }}-failure-logs
          path: |
            companies/${{ matrix.company }}/*.log
            companies/${{ matrix.company }}/*.png
          retention-days: 7
