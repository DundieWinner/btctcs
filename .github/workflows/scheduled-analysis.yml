name: Scheduled Company Analysis

on:
  schedule:
    # Run daily at 9:00 AM UTC
    - cron: '0 9 * * *'
  push:
    branches:
      - main
  workflow_dispatch:  # Allow manual triggering

jobs:
  discover-companies:
    runs-on: ubuntu-latest
    outputs:
      companies: ${{ steps.find-companies.outputs.companies }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Find companies with analysis scripts
        id: find-companies
        run: |
          companies=()
          for dir in companies/*/; do
            if [ -d "$dir" ] && [ -f "${dir}analysis_with_upload.py" ]; then
              company_name=$(basename "$dir")
              companies+=("$company_name")
            fi
          done
          
          # Convert array to JSON format for matrix strategy
          if [ ${#companies[@]} -eq 0 ]; then
            companies_json="[]"
          else
            companies_json=$(printf '%s\n' "${companies[@]}" | jq -R . | jq -s .)
          fi
          echo "companies=$companies_json" >> $GITHUB_OUTPUT
          
          echo "Found companies: ${companies[*]}"

  run-analysis:
    needs: discover-companies
    if: ${{ needs.discover-companies.outputs.companies != '[]' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        company: ${{ fromJson(needs.discover-companies.outputs.companies) }}
      fail-fast: false  # Continue running other companies even if one fails
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ${{ matrix.company }} analysis
        env:
          # S3 Configuration
          S3_BUCKET_NAME: btctcs
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: nyc3
          AWS_ENDPOINT_URL: https://nyc3.digitaloceanspaces.com
          S3_KEY_PREFIX: charts
          
          # Data Configuration
          H100_DATA_URL: ${{ secrets.H100_DATA_URL }}
        run: |
          echo "Running analysis for company: ${{ matrix.company }}"
          cd companies/${{ matrix.company }}
          python analysis_with_upload.py

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.company }}-failure-logs
          path: |
            companies/${{ matrix.company }}/*.log
            companies/${{ matrix.company }}/*.png
          retention-days: 7

  summary:
    needs: [discover-companies, run-analysis]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Analysis Summary
        run: |
          echo "## Analysis Summary" >> $GITHUB_STEP_SUMMARY
          echo "**Companies discovered:** ${{ needs.discover-companies.outputs.companies }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run status:** ${{ needs.run-analysis.result }}" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
